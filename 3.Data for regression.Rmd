---
title: "Data for regression"
author: "Pratyoosh Kashyap"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Import libraries:

```{r}
library(tidyverse)
library(haven) 
library(janitor) 

```

Import and merge data:

```{r}
#import the FTS Intensity (calculated using 2019 FTS Census) data:
intensity <- read_csv("int_sfa_regdata.csv") %>% clean_names()

#import community wealth data:
capitals <- read_csv("CapitalPCs061521.csv") %>% clean_names() %>% select(-c(county, stateansi, countyansi, fips2, county_2, state)) %>% rename(fips = fips1)

#import 2013 Rural-Urban Continuum Codes from USDA ERS (find here: https://www.ers.usda.gov/data-products/rural-urban-continuum-codes.aspx)
rucc <- read_csv("ruralurbancodes2013.csv") %>% clean_names() %>% select(-c(state, county_name, population_2010, description))

#import state policy environment:
policy <- read_csv("policy_2018_regdata.csv") %>% clean_names() %>% select(c(state_name, pol_proc, pol_educ, pol_other))

# merge the datasets:

merge1 <- left_join(intensity, capitals, by = "fips")

#merge rucc 2013
merge3 <- left_join(merge1, rucc, by = "fips")

#merge policy:
merge4 <- left_join(merge3, policy)
#Joining, by = "state_name"

merge4$fips <- as.numeric(merge4$fips)

# Drop those counties which have lower than 50% total student reported in the FTS Census vs. actual as reported by Common Core of Data.

#import county share of students - census data as a proportion of county ccd number:
county_std_share <- read_csv("county_std_share.csv") %>% clean_names()

#merge with main data set:

merge5 <- left_join(merge4, county_std_share)
#Joining, by = c("fips", "county")

#drop SFAs which are in counties with less than 50% student representation:
merge5 <- merge5 %>% filter(stdpercent>=50)

#Drop variables we do not need:
reg_all <- merge5 %>% select(-c(sfa_id, county, totalschools, state))

#export dataset:
write_csv(reg_all, "reg_data.csv", na="")

```

